---
title: homepage
date: 2024-12-11 01:24:19
tags:
academia: true
---
# About

I am a Machine Learning Researcher at [Apple MLR](https://machinelearning.apple.com/), specializing in Natural Language Processing (NLP) and Speech Technologies. 

## Academic Background
I completed my PhD in Computer Science at the University of Waterloo in 2023, with a dissertation titled "[Novel Methods for Natural Language Modeling and Pretraining](https://uwspace.uwaterloo.ca/items/7f8262f0-325b-4623-8996-edcd8fdbd780)", under the supervision of Professor [Ming Li](https://scholar.google.ca/citations?user=oGgPXFEAAAAJ&hl=en). 
Prior to my doctoral studies, I obtained a Master's degree from the Chinese Academy of Sciences, where I began my NLP research journey under the mentorship of Professor [Chengqing Zong](https://scholar.google.com.hk/citations?user=l8lvKOQAAAAJ&hl=en).

## Academic Service
I serve as an Area Chair for ACL Rolling Review and have been an active reviewer for top-tier NLP and ML conferences since 2019, including ACL, EMNLP, ICML, NeurIPS, and ICLR. My contributions were recognized with an Outstanding Reviewer Award at ICML 2022. Most recently, I organized a challenge track at the Embodied AI Workshop in CVPR 2024. 

## Research Interest
My research spans a broad and dynamic range of Natural Language Processing domains, including: language model pretraining, text-speech joint modeling, sentence representation learning, text summarization, machine translation, spoken language understanding, multilingual NLP, and information retrieval. 

Currently, I am deeply engaged in advancing audio and text sequence modeling, developing innovative approaches that push the boundaries of computational linguistics and machine learning.

# Selected Publications

**He Bai\***, Tatiana Likhomanenko\*, Ruixiang Zhang, Zijin Gu, Zakaria Aldeneh, Navdeep Jaitly. dMel: Speech tokenization made simple. Preprint.  [[pdf]](https://arxiv.org/abs/2407.15835) (*equal)

Y Zhang\*, **H Bai\***, R Zhang\*, J Gu, S Zhai, J Susskind, N Jaitly. How Far Are We from Intelligent Visual Deductive Reasoning? COLM 2024 [[pdf]](https://arxiv.org/abs/2403.04732)[[code]](https://github.com/apple/ml-rpm-bench). (*equal)

P Shi, L Song, L Jin, H Mi, **He Bai**, J Lin, D Yu. Cross-lingual Text-to-SQL Semantic Parsing with Representation Mixup. Findings of the Association for Computational Linguistics: EMNLP 2022, 5296-5306. 2022.

**He Bai\***, Renjie Zheng\*, Junkun Chen, Xintong Li, Mingbo Ma, Liang Huang. A3T: Alignment-Aware Acoustic and Text Pretraining for Speech Synthesis and Editing.  ICML 2022 [[pdf]](https://arxiv.org/abs/2203.09690)[[code]](https://github.com/richardbaihe/a3t). (*equal)

**He Bai**, Tong Wang, Alessandro Sordoni, Peng Shi. Better Language Model with Hypernym Class Prediction. ACL 2022 [[pdf]](https://openreview.net/pdf?id=YjZH6EpuSY) [[code]](https://github.com/richardbaihe/robustLM).

**He Bai**, Peng Shi, Jimmy Lin, Yuqing Xie, Luchen Tan, Kun Xiong, Wen Gao, Ming Li. Segatron: Segment-awareTransformer for Language Modeling and Understanding. AAAI 2021. (full paper) [[pdf]](https://arxiv.org/abs/2004.14996) [[code]](https://github.com/rsvp-ai/segatron_aaai)

**He Bai**, Peng Shi, Jimmy Lin, Luchen Tan, Kun Xiong, Wen Gao, Jie Liu, Ming Li. Semantics of the Unwritten: The Effect of End of Paragraph and Sequence Tokens on Text Generation. ACL-SRW 2021 (workshop paper) [[pdf]](https://arxiv.org/pdf/2004.02251.pdf) [[code]](https://github.com/rsvp-ai/semantic_unwritten).


**He Bai**, Yu Zhou, Jiajun Zhang and Chengqing Zong. Memory Consolidation for Contextual Spoken Language Understanding with Dialogue Logistic Inference. ACL 2019. [[pdf]](https://arxiv.org/pdf/1906.01788.pdf) [[code]](https://github.com/richardbaihe/conslu)


**He Bai**, Yu Zhou, Jiajun Zhang, Liang Zhao, Mei-Yuh Hwang and Chengqing Zong. Source Critical Reinforcement Learning for Transferring Spoken Language Understanding to a New Language. COLING 2018. [[pdf]](https://arxiv.org/pdf/1808.06167.pdf) 





